{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spatialdata as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all 6 wells\n",
    "Control = sd.read_zarr('/storage/lingyuan2/STATES_data/cellline0101_C3control_2d_dr.zarr')\n",
    "Tg15min = sd.read_zarr('/storage/lingyuan2/STATES_data/cellline0101_B4Tg15min_2d_dr.zarr')\n",
    "Tg30min = sd.read_zarr('/storage/lingyuan2/STATES_data/cellline0101_B5Tg30min_2d_dr.zarr') \n",
    "Tg1h = sd.read_zarr('/storage/lingyuan2/STATES_data/cellline0101_B6Tg1h_2d_dr.zarr')\n",
    "Tg2h = sd.read_zarr('/storage/lingyuan2/STATES_data/cellline0101_C4Tg2h_2d_dr.zarr')\n",
    "Tg4h = sd.read_zarr('/storage/lingyuan2/STATES_data/cellline0101_C5Tg4h_2d_dr.zarr')\n",
    "\n",
    "# Process data for all wells\n",
    "points_df_Control = pd.DataFrame(json.loads(Control.tables[\"table\"].uns[\"points\"]))\n",
    "points_df_Tg15min = pd.DataFrame(json.loads(Tg15min.tables[\"table\"].uns[\"points\"]))\n",
    "points_df_Tg30min = pd.DataFrame(json.loads(Tg30min.tables[\"table\"].uns[\"points\"]))\n",
    "points_df_Tg1h = pd.DataFrame(json.loads(Tg1h.tables[\"table\"].uns[\"points\"]))\n",
    "points_df_Tg2h = pd.DataFrame(json.loads(Tg2h.tables[\"table\"].uns[\"points\"]))\n",
    "points_df_Tg4h = pd.DataFrame(json.loads(Tg4h.tables[\"table\"].uns[\"points\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add condition column to each dataframe\n",
    "points_df_Control['condition'] = 'Control'\n",
    "points_df_Tg15min['condition'] = 'Tg15min'\n",
    "points_df_Tg30min['condition'] = 'Tg30min'\n",
    "points_df_Tg1h['condition'] = 'Tg1h'\n",
    "points_df_Tg2h['condition'] = 'Tg2h'\n",
    "points_df_Tg4h['condition'] = 'Tg4h'\n",
    "\n",
    "# Concatenate all dataframes\n",
    "all_points_df = pd.concat([\n",
    "    points_df_Control,\n",
    "    points_df_Tg15min, \n",
    "    points_df_Tg30min,\n",
    "    points_df_Tg1h,\n",
    "    points_df_Tg2h,\n",
    "    points_df_Tg4h\n",
    "], ignore_index=True)\n",
    "\n",
    "all_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points_df[~all_points_df['DR'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping dictionary for conditions to numbers\n",
    "condition_map = {\n",
    "    'Control': 0,\n",
    "    'Tg15min': 1, \n",
    "    'Tg30min': 2,\n",
    "    'Tg1h': 3,\n",
    "    'Tg2h': 4,\n",
    "    'Tg4h': 5\n",
    "}\n",
    "\n",
    "# Create cell_idx column by subtracting 1 from cell and adding condition offset\n",
    "all_points_df['cell_idx'] = (all_points_df['cell'] - 1).astype(str) + '-' + all_points_df['condition'].map(condition_map).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "adata = sc.read_h5ad('/storage/lingyuan2/STATES_data/pseudotime.h5ad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where cell is 0\n",
    "filtered_points_df = all_points_df[all_points_df['cell'] != 0]\n",
    "\n",
    "# Store filtered dataframe in adata.uns\n",
    "adata.uns['points_df'] = filtered_points_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gene column by removing everything after underscore in feature_name\n",
    "points_df = adata.uns['points_df']\n",
    "points_df['gene'] = points_df['feature_name'].str.split('_').str[0]\n",
    "adata.uns['points_df'] = points_df\n",
    "adata.uns['points_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###DR_All\n",
    "\n",
    "# Get points dataframe\n",
    "points_df = adata.uns['points_df']\n",
    "\n",
    "# Group by cell_idx and gene, calculate mean DR (skipping nans)\n",
    "dr_means = points_df.groupby(['cell_idx', 'gene'])['DR'].apply(lambda x: x.mean(skipna=True)).reset_index()\n",
    "\n",
    "# Create sparse matrix with cell_idx as rows and genes as columns\n",
    "dr_matrix = pd.pivot_table(dr_means, values='DR', index='cell_idx', columns='gene')\n",
    "\n",
    "# Reorder rows and columns to match adata\n",
    "dr_matrix = dr_matrix.reindex(index=adata.obs.index, columns=adata.var.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as new layer\n",
    "adata.layers['DR_All'] = dr_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###DR_ntRNA\n",
    "\n",
    "# Get points dataframe and filter for ntRNA features\n",
    "points_df = adata.uns['points_df']\n",
    "ntRNA_df = points_df[points_df['feature_name'].str.endswith('_ntRNA')].copy()\n",
    "\n",
    "# Remove _ntRNA suffix from feature names\n",
    "ntRNA_df['gene'] = ntRNA_df['feature_name'].str.replace('_ntRNA', '')\n",
    "\n",
    "# Group by cell_idx and gene, calculate mean DR (skipping nans)\n",
    "dr_means = ntRNA_df.groupby(['cell_idx', 'gene'])['DR'].apply(lambda x: x.mean(skipna=True)).reset_index()\n",
    "\n",
    "# Create sparse matrix with cell_idx as rows and genes as columns\n",
    "dr_matrix = pd.pivot_table(dr_means, values='DR', index='cell_idx', columns='gene')\n",
    "\n",
    "# Reorder rows and columns to match adata\n",
    "dr_matrix = dr_matrix.reindex(index=adata.obs.index, columns=adata.var.index)\n",
    "\n",
    "# Store as new layer\n",
    "adata.layers['DR_ntRNA'] = dr_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###DR_rbRNA\n",
    "\n",
    "# Get points dataframe and filter for rbRNA features\n",
    "points_df = adata.uns['points_df']\n",
    "rbRNA_df = points_df[points_df['feature_name'].str.endswith('_rbRNA')].copy()\n",
    "\n",
    "# Remove _rbRNA suffix from feature names\n",
    "rbRNA_df['gene'] = rbRNA_df['feature_name'].str.replace('_rbRNA', '')\n",
    "\n",
    "# Group by cell_idx and gene, calculate mean DR (skipping nans)\n",
    "dr_means = rbRNA_df.groupby(['cell_idx', 'gene'])['DR'].apply(lambda x: x.mean(skipna=True)).reset_index()\n",
    "\n",
    "# Create sparse matrix with cell_idx as rows and genes as columns\n",
    "dr_matrix = pd.pivot_table(dr_means, values='DR', index='cell_idx', columns='gene')\n",
    "\n",
    "# Reorder rows and columns to match adata\n",
    "dr_matrix = dr_matrix.reindex(index=adata.obs.index, columns=adata.var.index)\n",
    "\n",
    "# Store as new layer\n",
    "adata.layers['DR_rbRNA'] = dr_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save adata object to h5ad file\n",
    "adata.write_h5ad('/storage/lingyuan2/STATES_data/withDR.h5ad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the saved h5ad file\n",
    "import anndata as ad\n",
    "adataDR = ad.read_h5ad('/storage/lingyuan2/STATES_data/withDR.h5ad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adataDR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigfish_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
